{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import time as time\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import chain\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from itertools import zip_longest\n",
    "\n",
    "import src.numpy_utility as pnu\n",
    "from src.plots import display_candidate_loss\n",
    "from src.file_utility import save_stuff, flatten_dict, embed_dict\n",
    "from src.torch_fwrf import get_value\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from visualize import center_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "\n",
    "parser = argparse.ArgumentParser(prog='encoding model', \n",
    "\tdescription='input subject ID and gpu, output saved parameters',\n",
    "\tusage='python fwrf_ROIvoxel_mean.py --subj i --gpu j')\n",
    "\n",
    "# parser.add_argument('--subj', type=int)\n",
    "# parser.add_argument('--gpu', type=int)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "nsd_root = 'Z:/CNAI2/Mansoure_NSD/'\n",
    "stim_root = nsd_root + \"nsd_stimuli/\"\n",
    "beta_root = nsd_root + \"nsd_beta/\"\n",
    "#mask_root = nsd_root + \"mask/ppdata/\"\n",
    "#roi_root = nsd_root + \"freesurfer/\"\n",
    "meanROIbeta_root = nsd_root + \"roiavgbeta/\"\n",
    "\n",
    "exp_design_file = nsd_root + \"experiments/nsd_expdesign.mat\"\n",
    "stim_file       = stim_root + \"nsd_stimuli.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available? True\n",
      "#device: 1\n",
      "device#: 0\n",
      "device name: NVIDIA T400\n",
      "\n",
      "torch: 2.1.2\n",
      "cuda:  12.1\n",
      "Time Stamp: Dec-21-2023_1556\n"
     ]
    }
   ],
   "source": [
    "# set up cuda and parameters\n",
    "\n",
    "# test cuda\n",
    "print(\"Cuda available?\", torch.cuda.is_available())\n",
    "\n",
    "print ('#device:', torch.cuda.device_count())\n",
    "print ('device#:', torch.cuda.current_device())\n",
    "print ('device name:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "torch.manual_seed(time.time())\n",
    "#device = torch.device(\"cuda:%d\"%args.gpu) #cuda\n",
    "device = torch.device(\"cuda\") #cuda\n",
    "torch.backends.cudnn.enabled=True\n",
    "\n",
    "print ('\\ntorch:', torch.__version__)\n",
    "print ('cuda: ', torch.version.cuda)\n",
    "\n",
    "subject = 1\n",
    "saveext = \".png\"\n",
    "savearg = {'format':'png', 'dpi': 120, 'facecolor': None}\n",
    "timestamp = time.strftime('%b-%d-%Y_%H%M', time.localtime())\n",
    "model_name = 'dnn_fwrf'\n",
    "\n",
    "root_dir   = os.getcwd() + '/'\n",
    "net_dir    = root_dir + \"net/\" \n",
    "#input_dir  = '/home/styvesg/repo.data/results/nsd/torch_fwrf_full_brain/S%02d/dnn_fwrf_May-10-2020_1814/'\n",
    "output_dir = root_dir + \"output/S%02d/%s_%s/\" % (subject,model_name,timestamp) \n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "print (\"Time Stamp: %s\" % timestamp)\n",
    "\n",
    "exp_design = loadmat(exp_design_file)\n",
    "ordering = exp_design['masterordering'].flatten() - 1 # zero-indexed ordering of indices (matlab-like to python-like)\n",
    "subject_idx  = exp_design['subjectim']\n",
    "\n",
    "#stim_pattern = exp_design['stimpattern']\n",
    "#shared_idx   = exp_design['sharedix']\n",
    "#basic_cnt    = exp_design['basiccnt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before preprocessing (73000, 425, 425, 3)\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n"
     ]
    }
   ],
   "source": [
    "# do not need to run again\n",
    "image_data_set_all = h5py.File(stim_file, 'r')\n",
    "image_data_all = np.copy(image_data_set_all['imgBrick'])\n",
    "image_data_set_all.close()\n",
    "print('before preprocessing',image_data_all.shape)\n",
    "\n",
    "for k,s_idx in enumerate(subject_idx):\n",
    "    s_image_data = image_data_all[s_idx - 1]\n",
    "    s_image_data = np.transpose(s_image_data, (0,3,1,2))\n",
    "    s_image_data = center_crop(s_image_data, 425, 227)\n",
    "\n",
    "    save_stuff(\"%sS%d_stimuli_%d\"%(stim_root, k+1, 227), {'stimuli': s_image_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image\n",
    "\n",
    "# image_data_set = h5py.File(stim_root + \"S%d_stimuli_227.h5py\"%subject, 'r')\n",
    "# image_data = np.copy(image_data_set['stimuli']).astype(np.float32) / 255.\n",
    "# image_data_set.close()\n",
    "\n",
    "# load shared stimuli id\n",
    "# shared_stimuli_id = pd.read_csv(stim_root + 'shared1000.txt', sep='\\t', header=None)\n",
    "\n",
    "# f = h5py.File(stim_file, 'r+')\n",
    "# image_data = np.copy(f['imgBrick'][shared_stimuli_id[0]-1,:,:,:])\n",
    "# f.close()\n",
    "\n",
    "# image_data = image_data.astype(np.float32) / 255\n",
    "\n",
    "\n",
    "# print (image_data.shape)\n",
    "# print (image_data.dtype)\n",
    "# print (np.min(image_data[0]), np.max(image_data[0]))\n",
    "\n",
    "\n",
    "# image_data_set = h5py.File(stim_root + \"S%d_stimuli_227.h5py\"%subject, 'r')\n",
    "# image_data = np.copy(image_data_set['stimuli']).astype(np.float32) / 255.\n",
    "# image_data_set.close()\n",
    "\n",
    "# print (image_data.shape)\n",
    "# print (image_data.dtype)\n",
    "# print (np.min(image_data[0]), np.max(image_data[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation size = 3000 , Training size = 27000\n",
      "(30000,)\n",
      "cudnn: 8801\n",
      "dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_data_set = h5py.File(stim_root + \"S%d_stimuli_227.h5py\"%subject, 'r')\n",
    "image_data = np.copy(image_data_set['stimuli']).astype(np.float32) / 255.\n",
    "image_data_set.close()\n",
    "\n",
    "print (image_data.shape)\n",
    "print (image_data.dtype)\n",
    "print (np.min(image_data[0]), np.max(image_data[0]))\n",
    "\n",
    "trials = np.array([30000, 30000, 24000, 22500, 30000, 24000, 30000, 22500])\n",
    "data_size = trials[subject-1]\n",
    "ordering_data = ordering[:data_size]\n",
    "shared_mask   = ordering_data<1000  # the first 1000 indices are the shared indices\n",
    "\n",
    "val_size = np.sum(shared_mask)\n",
    "trn_size = data_size - val_size\n",
    "print (\"Validation size =\", val_size, \", Training size =\", trn_size)\n",
    "print(ordering_data.shape)\n",
    "\n",
    "stim_data = image_data[ordering_data]  # reduce to only the samples available thus far\n",
    "\n",
    "trn_stim_data = stim_data[~shared_mask]\n",
    "val_stim_data = stim_data[shared_mask]\n",
    "\n",
    "val_image_data = image_data[:1000]\n",
    "\n",
    "print ('cudnn:', torch.backends.cudnn.version())\n",
    "print ('dtype:', torch.get_default_dtype())\n",
    "#torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load beta\n",
    "\n",
    "ROIs = ['OFA', 'FFA1', 'FFA2', 'mTLfaces', 'aTLfaces', 'EBA', 'FBA1', 'FBA2', 'mTLbodies', 'OPA', 'PPA', 'RSC', 'OWFA', 'VWFA1', 'VWFA2', 'mfswords', 'mTLwords', 'V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4']\n",
    "#ROIs = ['L_hippocampus', 'L_amygdala', 'R_hippocampus', 'R_amygdala']\n",
    "roi_num = len(ROIs)\n",
    "roi_data = np.zeros([data_size, roi_num])\n",
    "n = 0\n",
    "del_idx = []\n",
    "for roi in ROIs:\n",
    "    roi_data[:,n] = np.genfromtxt(meanROIbeta_root + 'subj%02d/meanbeta_'%subject + roi + '.txt')\n",
    "    if np.isnan(np.sum(roi_data[:,n])):\n",
    "    \tdel_idx.append(n)\n",
    "    n += 1\n",
    "\n",
    "roi_data = np.delete(roi_data, del_idx, axis=1)\n",
    "\n",
    "trn_roi_data = roi_data[~shared_mask]\n",
    "val_roi_data = roi_data[shared_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 64, 27, 27])\n",
      "torch.Size([100, 192, 27, 27])\n",
      "torch.Size([100, 384, 13, 13])\n",
      "torch.Size([100, 256, 13, 13])\n",
      "torch.Size([100, 256, 13, 13])\n",
      "torch.Size([100, 4096, 1, 1])\n",
      "torch.Size([100, 4096, 1, 1])\n",
      "torch.Size([100, 1000, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:05,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0, shape=(100, 64, 27, 27)\n",
      "layer: 1, shape=(100, 192, 27, 27)\n",
      "layer: 2, shape=(100, 384, 13, 13)\n",
      "layer: 3, shape=(100, 256, 13, 13)\n",
      "layer: 4, shape=(100, 256, 13, 13)\n",
      "layer: 5, shape=(100, 512, 1, 1)\n",
      "layer: 6, shape=(100, 512, 1, 1)\n",
      "layer: 7, shape=(100, 512, 1, 1)\n",
      "\n",
      "fmaps: 0, shape=(100, 256, 27, 27)\n",
      "fmaps: 1, shape=(100, 896, 13, 13)\n",
      "fmaps: 2, shape=(100, 1536, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 256, 27, 27])\n",
      "torch.Size([100, 896, 13, 13])\n",
      "torch.Size([100, 1536, 1, 1])\n",
      "candidate count =  875\n",
      "trn_size = 24000 (88.9%)\n",
      "dtype = <class 'numpy.float32'>\n",
      "device = cuda:0\n",
      "---------------------------------------\n",
      "torch.Size([200, 256, 27, 27])\n",
      "torch.Size([200, 896, 13, 13])\n",
      "torch.Size([200, 1536, 1, 1])\n",
      "---------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#_log_act_func = lambda _x: torch.log(1 + torch.abs(_x))*torch.tanh(torch.abs(_x))\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_fwrf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  learn_params_ridge_regression, get_predictions, Torch_fwRF_voxel_block\n\u001b[1;32m---> 42\u001b[0m best_losses, best_lambdas, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mlearn_params_ridge_regression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrn_stim_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrn_roi_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_fmaps_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambdas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43maperture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maperture\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_nonlinearity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzscore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvoxel_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvoxel_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholdout_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholdout_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m ([p\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m best_params])\n\u001b[0;32m     48\u001b[0m param_batch \u001b[38;5;241m=\u001b[39m [p[:voxel_batch_size] \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m best_params]\n",
      "File \u001b[1;32mc:\\Users\\mjahani\\NSD_fMRI\\NeuroGen\\src\\torch_fwrf.py:203\u001b[0m, in \u001b[0;36mlearn_params_ridge_regression\u001b[1;34m(data, voxels, _fmaps_fn, models, lambdas, aperture, _nonlinearity, zscore, sample_batch_size, voxel_batch_size, holdout_size, shuffle, add_bias)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m#############################################################################        \u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m### Create full model value buffers    \u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m best_models \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(shape\u001b[38;5;241m=\u001b[39m(nv,), fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)   \n\u001b[0;32m    204\u001b[0m best_lambdas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(shape\u001b[38;5;241m=\u001b[39m(nv,), fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint)\n\u001b[0;32m    205\u001b[0m best_losses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(fill_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, shape\u001b[38;5;241m=\u001b[39m(nv), dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\mjahani\\Anaconda3\\envs\\cudatest\\Lib\\site-packages\\numpy\\__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "\n",
    "# load feature maps\n",
    "from torchmodel.models.alexnet import Alexnet_fmaps\n",
    "_fmaps_fn = Alexnet_fmaps().to(device)\n",
    "\n",
    "_x = torch.tensor(image_data[:100]).to(device) # the input variable.\n",
    "_fmaps = _fmaps_fn(_x)\n",
    "for k,_fm in enumerate(_fmaps):\n",
    "    print (_fm.size())\n",
    "\n",
    "from src.torch_feature_space import filter_dnn_feature_maps\n",
    "\n",
    "# I used image_data because the repeats are not relevant\n",
    "_fmaps_fn, lmask, fmask, tuning_masks = filter_dnn_feature_maps(image_data, _fmaps_fn, batch_size=100, fmap_max=512)\n",
    "\n",
    "_x = torch.tensor(image_data[:100]).to(device) # the input variable.\n",
    "_fmaps = _fmaps_fn(_x)\n",
    "for k,_fm in enumerate(_fmaps):\n",
    "    print (_fm.size())\n",
    "\n",
    "from src.rf_grid    import linspace, logspace, model_space, model_space_pyramid\n",
    "from src.torch_fwrf import learn_params_ridge_regression, get_predictions\n",
    "\n",
    "aperture = np.float32(1)\n",
    "nx = ny = 11\n",
    "smin, smax = np.float32(0.04), np.float32(0.4)\n",
    "ns = 8\n",
    "\n",
    "# sharedModel specification is a list of 3 ranges and 3 callable functor. The reason for this is for a future implementation of dynamic mesh refinement.\n",
    "#model_specs = [[(0., aperture*1.1), (0., aperture*1.1), (smin, smax)], [linspace(nx), linspace(ny), logspace(ns)]]\n",
    "#models = model_space(model_specs)\n",
    "models = model_space_pyramid(logspace(ns)(smin, smax), min_spacing=1.4, aperture=1.1*aperture)\n",
    "print ('candidate count = ', len(models))\n",
    "\n",
    "sample_batch_size = 200\n",
    "voxel_batch_size = 500\n",
    "holdout_size = 3000\n",
    "lambdas = np.logspace(3.,7.,9, dtype=np.float32)\n",
    "#_log_act_func = lambda _x: torch.log(1 + torch.abs(_x))*torch.tanh(torch.abs(_x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_size = 24000 (88.9%)\n",
      "dtype = <class 'numpy.float32'>\n",
      "device = cuda:0\n",
      "---------------------------------------\n",
      "torch.Size([200, 256, 27, 27])\n",
      "torch.Size([200, 896, 13, 13])\n",
      "torch.Size([200, 1536, 1, 1])\n",
      "---------------------------------------\n",
      "\n",
      "model  874 of 875 , voxels [     0:21    ] of 22\n",
      "---------------------------------------\n",
      "total time = 464835.001269s\n",
      "total throughput = 21128.863694s/voxel\n",
      "voxel throughput = 1740.312481s/voxel\n",
      "setup throughput = 487.483573s/model\n",
      "[(22, 3), (22, 2688), (22,), (22, 2688), (22, 2688)]\n"
     ]
    }
   ],
   "source": [
    "from torch_fwrf import learn_params_ridge_regression, get_predictions, Torch_fwRF_voxel_block\n",
    "\n",
    "best_losses, best_lambdas, best_params = learn_params_ridge_regression(\n",
    "    trn_stim_data, trn_roi_data, _fmaps_fn, models, lambdas, \\\n",
    "    aperture=aperture, _nonlinearity=None, zscore=True, sample_batch_size=sample_batch_size, \\\n",
    "    voxel_batch_size=voxel_batch_size, holdout_size=holdout_size, shuffle=False, add_bias=True)\n",
    "\n",
    "print ([p.shape if p is not None else None for p in best_params])\n",
    "param_batch = [p[:voxel_batch_size] if p is not None else None for p in best_params]\n",
    "_fwrf_fn = Torch_fwRF_voxel_block(_fmaps_fn, param_batch, _nonlinearity=None, input_shape=image_data.shape, aperture=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 22)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test some results\n",
    "val_voxel_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 916.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dec-21-2023_1556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate\n",
    "\n",
    "voxel_pred = get_predictions(val_image_data, _fmaps_fn, _fwrf_fn, best_params, sample_batch_size=sample_batch_size)\n",
    "\n",
    "val_voxel_pred = voxel_pred[ordering[:data_size][shared_mask]]\n",
    "val_cc  = np.zeros(shape=(val_voxel_pred.shape[1]))\n",
    "for v in tqdm(range(val_voxel_pred.shape[1])):    \n",
    "    val_cc[v] = np.corrcoef(val_roi_data[:,v], val_voxel_pred[:,v])[0,1]  \n",
    "val_cc = np.nan_to_num(val_cc)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "model_params = {\n",
    "    'lmask': lmask,\n",
    "    'fmask': fmask,\n",
    "    'tuning_masks': tuning_masks,\n",
    "    'aperture': aperture,\n",
    "    #'voxel_mask': voxel_mask,\n",
    "    #'brain_nii_shape': np.array(brain_nii_shape),\n",
    "    'val_size': val_size,\n",
    "    'trn_size': trn_size,\n",
    "    'shared_mask': shared_mask,\n",
    "    'image_order': ordering_data,\n",
    "    #'voxel_index': voxel_idx,\n",
    "    #'voxel_roi': voxel_roi,\n",
    "    'params': best_params,\n",
    "    'lambdas': lambdas, \n",
    "    'best_lambdas': best_lambdas,\n",
    "    'val_cc': val_cc,\n",
    "    }\n",
    "\n",
    "print (timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved lmask@0 in h5py file\n",
      "saved lmask@1 in h5py file\n",
      "saved lmask@2 in h5py file\n",
      "saved fmask@0 in h5py file\n",
      "saved fmask@1 in h5py file\n",
      "saved fmask@2 in h5py file\n",
      "saved tuning_masks@0 in h5py file\n",
      "saved tuning_masks@1 in h5py file\n",
      "saved tuning_masks@2 in h5py file\n",
      "saved tuning_masks@3 in h5py file\n",
      "saved tuning_masks@4 in h5py file\n",
      "saved tuning_masks@5 in h5py file\n",
      "saved tuning_masks@6 in h5py file\n",
      "saved tuning_masks@7 in h5py file\n",
      "saved aperture in h5py file\n",
      "saved val_size in h5py file\n",
      "saved trn_size in h5py file\n",
      "saved shared_mask in h5py file\n",
      "saved image_order in h5py file\n",
      "saved params@0 in h5py file\n",
      "saved params@1 in h5py file\n",
      "saved params@2 in h5py file\n",
      "saved params@3 in h5py file\n",
      "saved params@4 in h5py file\n",
      "saved lambdas in h5py file\n",
      "saved best_lambdas in h5py file\n",
      "saved val_cc in h5py file\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save results\n",
    "\n",
    "save_dir = root_dir + \"myoutput/S%02d/%s_%s/\" % (subject,model_name,timestamp) \n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "save_stuff(save_dir + \"model_params\", flatten_dict(model_params))\n",
    "\n",
    "ROIs_label = ['OFA', 'FFA1', 'FFA2', 'mTL \\n faces', 'aTL \\n faces', 'EBA', 'FBA1', 'FBA2', 'mTL \\n bodies', 'OPA', 'PPA', 'RSC', 'OWFA', 'VWFA1', 'VWFA2', 'mfs \\n words', 'mTL \\n words', 'V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4']\n",
    "#ROIs_label = ['L_hippocampus', 'L_amygdala', 'R_hippocampus', 'R_amygdala']\n",
    "ROIs_label = np.delete(ROIs_label,del_idx) \n",
    "plt.figure(figsize=(16,6))\n",
    "plt.bar(ROIs_label,val_cc)\n",
    "plt.savefig(save_dir + 'acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Memorability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
